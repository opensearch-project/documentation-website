---
layout: default
title: LLM framework integration
nav_order: 75
---

# LLM framework integration

Several popular large language model (LLM) frameworks integrate with OpenSearch as a vector store, enabling you to build production-ready generative AI applications. These frameworks provide high-level abstractions and tools for working with LLMs, and their OpenSearch integrations allow you to use OpenSearch for efficient vector storage, retrieval, and similarity search:

- LangChain 
    - [Semantic cache](https://python.langchain.com/docs/integrations/llm_caching/#opensearch-semantic-cache)
    - [Vector store support](https://python.langchain.com/docs/integrations/vectorstores/opensearch/)
 
- LlamaIndex
    - [Vector store support](https://docs.llamaindex.ai/en/stable/examples/vector_stores/OpensearchDemo/)
 
- FlowiseAI: 
    - [Vector store support](https://docs.flowiseai.com/integrations/langchain/vector-stores/opensearch)
 
- Langflow: 
    - [Vector store support](https://docs.langflow.org/components-vector-stores#opensearch)
 
- Haystack:  
    - [Vector store support](https://haystack.deepset.ai/integrations/opensearch-document-store)